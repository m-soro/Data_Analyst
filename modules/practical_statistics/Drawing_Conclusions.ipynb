{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Errors\n",
    "\n",
    "Here are two datasets that represent two of the examples you have seen in this lesson.  \n",
    "\n",
    "One dataset is based on the parachute example, and the second is based on the judicial example.  Neither of these datasets is based on real people.\n",
    "\n",
    "Use the exercises below to assist in answering the quiz questions at the bottom of this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "jud_data = pd.read_csv('judicial_dataset_predictions.csv')\n",
    "par_data = pd.read_csv('parachute_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>defendant_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22574</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35637</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39919</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29610</td>\n",
       "      <td>guilty</td>\n",
       "      <td>guilty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38273</td>\n",
       "      <td>innocent</td>\n",
       "      <td>innocent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   defendant_id    actual predicted\n",
       "0         22574  innocent  innocent\n",
       "1         35637  innocent  innocent\n",
       "2         39919  innocent  innocent\n",
       "3         29610    guilty    guilty\n",
       "4         38273  innocent  innocent"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Above, you can see the actual and predicted columns for each of the datasets.  Using the **jud_data**, find the proportion of errors for the dataset, and furthermore, the percentage of errors of each type.  Use the results to answer the questions in quiz 1 below.  \n",
    "\n",
    "**Hint for quiz:** an error is any time the prediction doesn't match an actual value.  Additionally, there are Type I and Type II errors to think about.  We also know we can minimize one type of error by maximizing the other type of error.  If we predict all individuals as innocent, how many of the guilty are incorrectly labeled?  Similarly, if we predict all individuals as guilty, how many of the innocent are incorrectly labeled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type 1 error: [actual *innocent*] [predicted *guilty*]\n",
    "# type 2 error: [actual *guilty*] [predicted *innocent*]\n",
    "\n",
    "type1 = jud_data.query('actual == \"innocent\" & predicted == \"guilty\"').actual.count()\n",
    "type2 = jud_data.query('actual == \"guilty\" & predicted == \"innocent\"').actual.count()\n",
    "correct = jud_data.query('actual == \"guilty\" & predicted == \"guilty\" or \\\n",
    "            actual == \"innocent\" & predicted == \"innocent\"').actual.count()\n",
    "innocent = jud_data.query('actual == \"innocent\"').actual.count()\n",
    "guilty = jud_data.query('actual == \"guilty\"').actual.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Percentage of Errors:  4.21529589455\n",
      "Percentage of Type I Error:  0.151036660717\n",
      "Percentage of Type II Error:  4.06425923383\n",
      "\n",
      "If everyone was predicted to be guilty\n",
      "\tthe percentage of Type I Errors made :  45.1599615543 \n",
      "\n",
      "\n",
      "If everyone was predicted to be guilty\n",
      "\tthe proportion of Type II Errors made :  0\n"
     ]
    }
   ],
   "source": [
    "# proportion of error rates\n",
    "\n",
    "type1_rate = type1/jud_data.shape[0]\n",
    "type2_rate = type2/jud_data.shape[0]\n",
    "innocent_rate = innocent/jud_data.shape[0]\n",
    "guilty_rate = guilty/jud_data.shape[0]\n",
    "\n",
    "print('Total Percentage of Errors: ', (type1_rate + type2_rate)*100 )\n",
    "print('Percentage of Type I Error: ', type1_rate * 100 )\n",
    "print('Percentage of Type II Error: ', type2_rate * 100 )\n",
    "print('\\nIf everyone was predicted to be guilty') \n",
    "print('\\tthe percentage of Type I Errors made : ', innocent_rate*100,'\\n')\n",
    "print('\\nIf everyone was predicted to be guilty') \n",
    "print('\\tthe proportion of Type II Errors made : ', 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that all the innocent individuals would be Type I Errors if everyone was predicted as guilty. What proportion of the dataset is innocent?\n",
    "\n",
    "* Notice that Type II Errors are individuals where guilty individuals are predicted as innocent. If everyone is predicted as guilty, what proportion of the time would we commit Type II Errors then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Using the **par_data**, find the proportion of errors for the dataset, and furthermore, the percentage of errors of each type.  Use the results to answer the questions in quiz 2 below.\n",
    "\n",
    "These should be very similar operations to those you performed in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parachute_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3956</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2147</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8325</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6598</td>\n",
       "      <td>opens</td>\n",
       "      <td>opens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parachute_id actual predicted\n",
       "0          3956  opens     opens\n",
       "1          2147  opens     opens\n",
       "2          2024  opens     opens\n",
       "3          8325  opens     opens\n",
       "4          6598  opens     opens"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type 1 error: [actual: *fails* predicted: *opens*]\n",
    "# type 2 error: [actual: *opens* predicted: *fails*]\n",
    "\n",
    "type1 = par_data.query('actual == \"fails\" & predicted == \"opens\"').actual.count()\n",
    "type2 = par_data.query('actual == \"opens\" & predicted == \"fails\"').actual.count()\n",
    "correct = par_data.query('actual == \"fails\" & predicted == \"fails\" or \\\n",
    "            actual == \"opens\" & predicted == \"opens\"').actual.count()\n",
    "opens = par_data.query('actual == \"opens\"').actual.count()\n",
    "fails = jud_data.query('actual == \"fails\"').actual.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Proportion of Errors:  0.0526676960027\n",
      "Proportion of Type I Error:  0.00188711614342\n",
      "Proportion of Type II Error:  0.0507805798593\n",
      "\n",
      "If every parachute was predicted to not open,\n",
      "\tthe proportion of Type I Errors made 0 \n",
      "\n",
      "If every parachute was predicted to not open,\n",
      "\tthe proportion of Type II Errors made 0.991765311374\n"
     ]
    }
   ],
   "source": [
    "# proportion of error rates\n",
    "\n",
    "type1_rate = type1/par_data.shape[0]\n",
    "type2_rate = type2/par_data.shape[0]\n",
    "opens_rate = opens/par_data.shape[0]\n",
    "fails_rate = fails/par_data.shape[0]\n",
    "\n",
    "print('Total Proportion of Errors: ', (type1_rate + type2_rate) )\n",
    "print('Proportion of Type I Error: ', type1_rate )\n",
    "print('Proportion of Type II Error: ', type2_rate )\n",
    "print('\\nIf every parachute was predicted to not open,'+\n",
    "      '\\n\\tthe proportion of Type I Errors made', 0,'\\n')\n",
    "print('If every parachute was predicted to not open,'+\n",
    "       '\\n\\tthe proportion of Type II Errors made', opens_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we predict all of the parachutes to fail, we would never commit a Type I Error.\n",
    "\n",
    "* If we predict all of the parachutes to fail, we would commit a Type II Error on every parachute that actually opens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
